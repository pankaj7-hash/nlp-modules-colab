{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuUCz5iX7m7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc8714b0-71c1-4bbb-f163-ce0dc5e8e006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW Vocabulary: ['and' 'boring' 'great' 'hate' 'inspiring' 'is' 'love' 'movie' 'not'\n",
            " 'this']\n",
            "BoW Matrix:\n",
            " [[0 0 0 0 0 0 1 1 0 1]\n",
            " [1 0 1 0 1 1 0 1 0 1]\n",
            " [0 1 0 1 0 0 0 1 0 1]\n",
            " [0 0 1 0 0 1 0 1 1 1]]\n",
            "\n",
            "TF-IDF Vocabulary: ['and' 'boring' 'great' 'hate' 'inspiring' 'is' 'love' 'movie' 'not'\n",
            " 'this']\n",
            "TF-IDF Matrix:\n",
            " [[0.         0.         0.         0.         0.         0.\n",
            "  0.8046125  0.41988018 0.         0.41988018]\n",
            " [0.51381313 0.         0.40509617 0.         0.51381313 0.40509617\n",
            "  0.         0.268129   0.         0.268129  ]\n",
            " [0.         0.62688384 0.         0.62688384 0.         0.\n",
            "  0.         0.32713399 0.         0.32713399]\n",
            " [0.         0.         0.47219392 0.         0.         0.47219392\n",
            "  0.         0.31254032 0.59891811 0.31254032]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "docs = [\n",
        "    \"I love this movie\",\n",
        "    \"This movie is great and inspiring\",\n",
        "    \"I hate this boring movie\",\n",
        "    \"This movie is not great\"\n",
        "]\n",
        "\n",
        "# Bag of Words\n",
        "cv = CountVectorizer()\n",
        "bow = cv.fit_transform(docs)\n",
        "print(\"BoW Vocabulary:\", cv.get_feature_names_out())\n",
        "print(\"BoW Matrix:\\n\", bow.toarray())\n",
        "\n",
        "# TF-IDF\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(docs)\n",
        "print(\"\\nTF-IDF Vocabulary:\", tfidf.get_feature_names_out())\n",
        "print(\"TF-IDF Matrix:\\n\", tfidf_matrix.toarray())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "sentences = [\n",
        "    [\"i\", \"love\", \"nlp\"],\n",
        "    [\"nlp\", \"is\", \"fun\"],\n",
        "    [\"i\", \"love\", \"machine\", \"learning\"]\n",
        "]\n",
        "\n",
        "model = Word2Vec(sentences, vector_size=5, window=2, min_count=1)\n",
        "print(model.wv[\"love\"])       # vector for \"love\"\n",
        "print(model.wv.most_similar(\"nlp\"))"
      ],
      "metadata": {
        "id": "Pe9GMz708Yuj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77da0642-38d4-4b72-9c44-da8e2283d5ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "[-0.14233617  0.12917745  0.17945977 -0.10030856 -0.07526743]\n",
            "[('i', 0.4593397080898285), ('love', 0.2018294781446457), ('learning', 0.10980252921581268), ('is', 0.04115491732954979), ('fun', -0.0006994149298407137), ('machine', -0.11398053169250488)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2-jxqQFr8Yxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.wv[\"love\"])\n"
      ],
      "metadata": {
        "id": "B6-1S84Y8Y0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1bb5f5c-0583-4c4e-8b4f-43e6a592a07a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.14233617  0.12917745  0.17945977 -0.10030856 -0.07526743]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.wv.most_similar(\"nlp\"))\n"
      ],
      "metadata": {
        "id": "L1ar2qgw8Y3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed29ad07-9315-4a3c-f5ca-bf29377f8469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('i', 0.4593397080898285), ('love', 0.2018294781446457), ('learning', 0.10980252921581268), ('is', 0.04115491732954979), ('fun', -0.0006994149298407137), ('machine', -0.11398053169250488)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cosine Similarity"
      ],
      "metadata": {
        "id": "rDAu8kp1FZ1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"https://medium.com/data-science-collective/cosine-similarity-explained-the-math-behind-llms-b20caac9f93c#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6IjRmZWI0NGYwZjdhN2UyN2M3YzQwMzM3OWFmZjIwYWY1YzhjZjUyZGMiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJhenAiOiIyMTYyOTYwMzU4MzQtazFrNnFlMDYwczJ0cDJhMmphbTRsamRjbXMwMHN0dGcuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJhdWQiOiIyMTYyOTYwMzU4MzQtazFrNnFlMDYwczJ0cDJhMmphbTRsamRjbXMwMHN0dGcuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJzdWIiOiIxMDU3NzU3NDQ4NDk3NzE4NDU4MTEiLCJlbWFpbCI6ImxhdmFueWEuc3JpdmFAZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsIm5iZiI6MTc2MzA4NTExOSwibmFtZSI6ImxhdmFueWEgc3JpdmFzdGF2YSIsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NLTDExWFZiZGRsb3c1c1ZKbDRBUGtFYWtDSHVKTmtYbW90RDRKQnlpNHUyQm8xaGpHQk9BPXM5Ni1jIiwiZ2l2ZW5fbmFtZSI6ImxhdmFueWEiLCJmYW1pbHlfbmFtZSI6InNyaXZhc3RhdmEiLCJpYXQiOjE3NjMwODU0MTksImV4cCI6MTc2MzA4OTAxOSwianRpIjoiYjM2MzVkOTExNGJkODJlOTMzZjEwZGRlNzM1MmJkMmZmYmMzNDFlMTYifQ.KWI5VXuny4icBhuOGvbUbxbtGirpTfy9Wv2wteUg2FD0Q5-kTYkqT-1Dw3X4txqaRNGoB81mlxGkWKVp1O1NV6j3fA1fqvP_AIHACHrT0LTgnvKO3DdX3HQY6yhfHet51kAso7o5Ou1L87IywvmGfu9G7TA_1LhsuIaLz0zJD50UJe9L7Pxt5LtjAwEyPuPDzDvB4o0Aa3Oa-Wm3VqPE0OpV4iqSeMeyNMXXMgFWGpdDZqpMQKjdPYUztPBqDv-1aOpsWgeJz7Y1gcNdMsFWQWMq2FL90Ki6dN0CI-ixRg1fgx2YZ0YLz4t9T7CORRkAROFnlD1ZuaRyshGqhLcJQSg\")"
      ],
      "metadata": {
        "id": "5qgyqVOa8Y-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b56a708c-c9c4-493d-a63c-93c69b9c0433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://medium.com/data-science-collective/cosine-similarity-explained-the-math-behind-llms-b20caac9f93c#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6IjRmZWI0NGYwZjdhN2UyN2M3YzQwMzM3OWFmZjIwYWY1YzhjZjUyZGMiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJhenAiOiIyMTYyOTYwMzU4MzQtazFrNnFlMDYwczJ0cDJhMmphbTRsamRjbXMwMHN0dGcuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJhdWQiOiIyMTYyOTYwMzU4MzQtazFrNnFlMDYwczJ0cDJhMmphbTRsamRjbXMwMHN0dGcuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJzdWIiOiIxMDU3NzU3NDQ4NDk3NzE4NDU4MTEiLCJlbWFpbCI6ImxhdmFueWEuc3JpdmFAZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsIm5iZiI6MTc2MzA4NTExOSwibmFtZSI6ImxhdmFueWEgc3JpdmFzdGF2YSIsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NLTDExWFZiZGRsb3c1c1ZKbDRBUGtFYWtDSHVKTmtYbW90RDRKQnlpNHUyQm8xaGpHQk9BPXM5Ni1jIiwiZ2l2ZW5fbmFtZSI6ImxhdmFueWEiLCJmYW1pbHlfbmFtZSI6InNyaXZhc3RhdmEiLCJpYXQiOjE3NjMwODU0MTksImV4cCI6MTc2MzA4OTAxOSwianRpIjoiYjM2MzVkOTExNGJkODJlOTMzZjEwZGRlNzM1MmJkMmZmYmMzNDFlMTYifQ.KWI5VXuny4icBhuOGvbUbxbtGirpTfy9Wv2wteUg2FD0Q5-kTYkqT-1Dw3X4txqaRNGoB81mlxGkWKVp1O1NV6j3fA1fqvP_AIHACHrT0LTgnvKO3DdX3HQY6yhfHet51kAso7o5Ou1L87IywvmGfu9G7TA_1LhsuIaLz0zJD50UJe9L7Pxt5LtjAwEyPuPDzDvB4o0Aa3Oa-Wm3VqPE0OpV4iqSeMeyNMXXMgFWGpdDZqpMQKjdPYUztPBqDv-1aOpsWgeJz7Y1gcNdMsFWQWMq2FL90Ki6dN0CI-ixRg1fgx2YZ0YLz4t9T7CORRkAROFnlD1ZuaRyshGqhLcJQSg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Pretrained BERT model for sentiment\n",
        "analyzer = pipeline(\"sentiment-analysis\")\n",
        "print(analyzer(\"This movie was absolutely wonderful!\"))\n"
      ],
      "metadata": {
        "id": "30ao2E1P8ZBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e92de8-be48-4aab-95a8-c1167f68c0a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9998792409896851}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 1. MUCH BIGGER & REALISTIC DATASET (100 sentences)\n",
        "# ----------------------------------------------------\n",
        "\n",
        "positive_sentences = [\n",
        "    \"I loved this movie\", \"This film was absolutely amazing\",\n",
        "    \"Great acting and wonderful storyline\", \"The direction was superb\",\n",
        "    \"An emotional and heart touching film\", \"This movie made me happy\",\n",
        "    \"Fantastic experience overall\", \"A must watch movie\",\n",
        "    \"Beautiful script and engaging scenes\", \"Truly inspiring\",\n",
        "    \"The cast delivered excellent performances\", \"Cinematography was stunning\",\n",
        "    \"The music was soothing and memorable\", \"One of the best movies ever\",\n",
        "    \"Enjoyed every moment of this film\", \"The story was well written\",\n",
        "    \"A perfect blend of emotions and action\", \"Highly entertaining\",\n",
        "    \"I would love to watch it again\", \"Everything about this was great\",\n",
        "    \"Absolutely brilliant acting\", \"Exceeded my expectations\",\n",
        "    \"Very creative and thoughtful film\", \"Simply fantastic\",\n",
        "    \"The dialogues were powerful\", \"The pacing was perfect\",\n",
        "    \"Magnificent direction\", \"Wonderful film from start to end\",\n",
        "    \"Heartwarming and beautifully shot\", \"Truly enjoyable experience\",\n",
        "    # add more for robustness\n",
        "] * 2  # duplicate to reach ~60 (small simulation)\n",
        "\n",
        "negative_sentences = [\n",
        "    \"I hated this movie\", \"This film was terrible\",\n",
        "    \"Awful acting and poor storyline\", \"The direction was weak\",\n",
        "    \"A boring and dull movie\", \"This made me frustrated\",\n",
        "    \"Terrible experience overall\", \"Not worth watching\",\n",
        "    \"The script was confusing\", \"Very disappointing\",\n",
        "    \"The cast performed poorly\", \"Cinematography was bad\",\n",
        "    \"The music was irritating\", \"One of the worst movies\",\n",
        "    \"Did not enjoy any moment\", \"The story was badly written\",\n",
        "    \"The pacing was too slow\", \"Highly uninteresting\",\n",
        "    \"Would never watch this again\", \"Everything about this was bad\",\n",
        "    \"Absolutely pathetic acting\", \"Below expectations\",\n",
        "    \"Very poorly made film\", \"Simply horrible\",\n",
        "    \"The dialogues were weak\", \"Plot made no sense\",\n",
        "    \"Terrible editing\", \"Worst film of the year\",\n",
        "    \"Unpleasant and tiring\", \"A complete waste of time\",\n",
        "    # add more\n",
        "] * 2  # duplicate to reach ~60\n",
        "\n",
        "texts = positive_sentences + negative_sentences\n",
        "labels = [\"positive\"] * len(positive_sentences) + [\"negative\"] * len(negative_sentences)\n",
        "\n",
        "print(\"Total dataset size:\", len(texts))\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 2. TRAIN-TEST SPLIT\n",
        "# ----------------------------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 3. TF-IDF IMPROVED\n",
        "# ----------------------------------------------------\n",
        "tfidf = TfidfVectorizer(\n",
        "    stop_words=\"english\",      # removes useless words\n",
        "    ngram_range=(1,2),         # bigrams + unigrams ‚Äî HUGE BOOST\n",
        "    min_df=2                   # ignore extremely rare words\n",
        ")\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 4. TRAIN MODEL (IMPROVED ALPHA)\n",
        "# ----------------------------------------------------\n",
        "model = MultinomialNB(alpha=0.5)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 5. PREDICT & RESULTS\n",
        "# ----------------------------------------------------\n",
        "pred = model.predict(X_test_tfidf)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy_score(y_test, pred))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, pred))\n"
      ],
      "metadata": {
        "id": "Ko7dJaixF4sZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c7e693-a7d3-4b04-8ad7-b012acd04df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total dataset size: 120\n",
            "\n",
            "Accuracy: 0.8333333333333334\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.83      0.83      0.83        12\n",
            "    positive       0.83      0.83      0.83        12\n",
            "\n",
            "    accuracy                           0.83        24\n",
            "   macro avg       0.83      0.83      0.83        24\n",
            "weighted avg       0.83      0.83      0.83        24\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# üìå IMPORTING ALL REQUIRED LIBRARIES FOR SENTIMENT ANALYSIS\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "# Pandas ‚Äî for loading CSV files, cleaning data, and handling tables\n",
        "import pandas as pd\n",
        "\n",
        "# Train-test split ‚Äî to divide data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# TF-IDF Vectorizer ‚Äî converts text into numerical features (NLP preprocessing)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Naive Bayes classifier ‚Äî MultinomialNB works best for text classification\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Metrics to evaluate model performance\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ],
      "metadata": {
        "id": "37coJia-SjDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "80kG9Dy5SjG9",
        "outputId": "6946a4fc-b8ab-4e38-bb15-fe04cd162130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-282dcc2c-662d-495f-97ec-b8f07cdb0ebe\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-282dcc2c-662d-495f-97ec-b8f07cdb0ebe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving archive (11).zip to archive (11).zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# üì¶ CELL 3: UNZIP THE UPLOADED ZIP FILE\n",
        "# -------------------------------------------------------------\n",
        "# Purpose:\n",
        "# - You uploaded \"archive (11).zip\"\n",
        "# - Now we extract its contents so we can access the CSV file inside\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "import zipfile   # Python module for working with ZIP files\n",
        "import os        # For interacting with the operating system (paths, folders)\n",
        "\n",
        "# Name of the ZIP file you uploaded (shown in output of files.upload())\n",
        "zip_filename = \"archive (11).zip\"\n",
        "\n",
        "# Folder where we will extract everything\n",
        "extract_folder = \"dataset_folder\"\n",
        "\n",
        "# Create folder if it doesn't already exist\n",
        "if not os.path.exists(extract_folder):\n",
        "    os.makedirs(extract_folder)\n",
        "\n",
        "# Extract ZIP contents safely\n",
        "with zipfile.ZipFile(zip_filename, \"r\") as z:\n",
        "    z.extractall(extract_folder)\n",
        "\n",
        "print(\"‚úÖ ZIP extraction completed!\")\n",
        "print(\"üìÅ Extracted files:\", os.listdir(extract_folder))\n"
      ],
      "metadata": {
        "id": "uPsW-I_HVpNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d08fcb3-afe9-43d4-bd10-95aec04db0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ZIP extraction completed!\n",
            "üìÅ Extracted files: ['IMDB Dataset.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# üìö CELL 4: LOAD THE IMDB SENTIMENT DATASET (CSV FILE)\n",
        "# -------------------------------------------------------------\n",
        "# Purpose:\n",
        "# - After unzipping, we now locate \"IMDB Dataset.csv\"\n",
        "# - Load it into a pandas DataFrame for processing\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "\n",
        "# Path to the extracted folder (same folder used in Cell 3)\n",
        "extract_folder = \"dataset_folder\"\n",
        "\n",
        "# Full path to the IMDB CSV file inside the folder\n",
        "csv_path = os.path.join(extract_folder, \"IMDB Dataset.csv\")\n",
        "\n",
        "# Load the CSV into a DataFrame\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(\"‚úÖ Dataset loaded successfully!\")\n",
        "\n",
        "# Show first 5 rows to confirm that data is correct\n",
        "print(\"\\nüîπ First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Show column names to confirm structure\n",
        "print(\"\\nüîπ Column names:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Show shape (rows, columns)\n",
        "print(\"\\nüîπ Dataset shape:\")\n",
        "print(df.shape)\n"
      ],
      "metadata": {
        "id": "LoGXaPyvSjJ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6010f45b-37e0-4bda-e2a4-e153f3146df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset loaded successfully!\n",
            "\n",
            "üîπ First 5 rows of the dataset:\n",
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "\n",
            "üîπ Column names:\n",
            "Index(['review', 'sentiment'], dtype='object')\n",
            "\n",
            "üîπ Dataset shape:\n",
            "(50000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# üìä CELL 5: BASIC EXPLORATION OF THE IMDB DATASET\n",
        "# -------------------------------------------------------------\n",
        "# Purpose:\n",
        "# - Understand dataset structure and quality\n",
        "# - Check for missing values\n",
        "# - Check class balance of sentiments\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "# 1Ô∏è‚É£ Show summary info: data types + non-null counts\n",
        "print(\"üîπ Dataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "# 2Ô∏è‚É£ Check for missing values in each column\n",
        "print(\"\\nüîπ Missing values in each column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# 3Ô∏è‚É£ Check unique sentiments present\n",
        "print(\"\\nüîπ Unique sentiment labels:\")\n",
        "print(df['sentiment'].unique())\n",
        "\n",
        "# 4Ô∏è‚É£ Count how many positive vs negative reviews\n",
        "print(\"\\nüîπ Sentiment distribution (count):\")\n",
        "print(df['sentiment'].value_counts())\n",
        "\n",
        "# 5Ô∏è‚É£ Sentiment proportion (percentage)\n",
        "print(\"\\nüîπ Sentiment distribution (percentage):\")\n",
        "print(df['sentiment'].value_counts(normalize=True) * 100)\n"
      ],
      "metadata": {
        "id": "vfHhLiA_Vq3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf5168d-4e1b-446c-aa2d-7843a8a210a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n",
            "None\n",
            "\n",
            "üîπ Missing values in each column:\n",
            "review       0\n",
            "sentiment    0\n",
            "dtype: int64\n",
            "\n",
            "üîπ Unique sentiment labels:\n",
            "['positive' 'negative']\n",
            "\n",
            "üîπ Sentiment distribution (count):\n",
            "sentiment\n",
            "positive    25000\n",
            "negative    25000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üîπ Sentiment distribution (percentage):\n",
            "sentiment\n",
            "positive    50.0\n",
            "negative    50.0\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# üß© CELL 6: SELECT TEXT & LABEL COLUMNS + TRAIN‚ÄìTEST SPLIT\n",
        "# -------------------------------------------------------------\n",
        "# Purpose:\n",
        "# - Pick the input text column and target label column from df\n",
        "# - Create X (features) and y (labels)\n",
        "# - Split data into training and testing sets\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "# 1Ô∏è‚É£ Select the text and label columns\n",
        "\n",
        "# In the IMDB dataset:\n",
        "# - \"review\"   ‚Üí column containing movie review text\n",
        "# - \"sentiment\" ‚Üí column containing label (\"positive\" / \"negative\")\n",
        "\n",
        "X = df['review']      # Feature: input text\n",
        "y = df['sentiment']   # Target: sentiment label\n",
        "\n",
        "# Quick check: print first 3 examples\n",
        "print(\"üîπ Sample reviews (X):\")\n",
        "print(X.head(3))\n",
        "\n",
        "print(\"\\nüîπ Sample labels (y):\")\n",
        "print(y.head(3))\n",
        "\n",
        "\n",
        "# 2Ô∏è‚É£ Train‚ÄìTest Split\n",
        "# - We split data into:\n",
        "#     üü¶ Training set  ‚Üí used to train the model\n",
        "#     üü® Test set      ‚Üí used to evaluate the model on unseen data\n",
        "# - test_size=0.2  ‚Üí 20% test, 80% train\n",
        "# - stratify=y     ‚Üí keeps the positive/negative ratio same in train and test\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,              # input text\n",
        "    y,              # labels\n",
        "    test_size=0.2,  # 20% of data for testing\n",
        "    random_state=42,# for reproducibility\n",
        "    stratify=y      # maintain class balance\n",
        ")\n",
        "\n",
        "# 3Ô∏è‚É£ Print sizes to confirm the split\n",
        "print(\"\\n‚úÖ Train-test split completed!\")\n",
        "print(f\"Number of training samples: {len(X_train)}\")\n",
        "print(f\"Number of test samples: {len(X_test)}\")\n"
      ],
      "metadata": {
        "id": "-m9AJLL-UjBn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c359db-a496-4e18-d3b3-fd4597ee02d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Sample reviews (X):\n",
            "0    One of the other reviewers has mentioned that ...\n",
            "1    A wonderful little production. <br /><br />The...\n",
            "2    I thought this was a wonderful way to spend ti...\n",
            "Name: review, dtype: object\n",
            "\n",
            "üîπ Sample labels (y):\n",
            "0    positive\n",
            "1    positive\n",
            "2    positive\n",
            "Name: sentiment, dtype: object\n",
            "\n",
            "‚úÖ Train-test split completed!\n",
            "Number of training samples: 40000\n",
            "Number of test samples: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# üî§ CELL 7: TF-IDF VECTORIZATION (TEXT ‚Üí NUMBERS)\n",
        "# -------------------------------------------------------------\n",
        "# Purpose:\n",
        "# - Convert raw text into numerical vectors using TF-IDF\n",
        "# - Fit the vectorizer on training data ONLY (to avoid leakage)\n",
        "# - Transform both training and test data\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "# Create a TF-IDF vectorizer\n",
        "# Key parameters:\n",
        "# - stop_words='english' removes common words (the, is, and...)\n",
        "# - ngram_range=(1,2) includes unigrams + bigrams for better learning\n",
        "# - max_features limits vocabulary size for efficiency\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2),    # (word), (word1 word2)\n",
        "    max_features=5000      # limit to best 5000 features\n",
        ")\n",
        "\n",
        "# Fit the vectorizer on training data and transform it\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data (NO FITTING ON TEST)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Print shapes for confirmation\n",
        "print(\"‚úÖ TF-IDF Vectorization completed!\")\n",
        "print(f\"Shape of X_train_tfidf: {X_train_tfidf.shape}\")\n",
        "print(f\"Shape of X_test_tfidf:  {X_test_tfidf.shape}\")\n"
      ],
      "metadata": {
        "id": "2a62t-kMUjEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29040290-e57c-4fe0-c654-a999608c420a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ TF-IDF Vectorization completed!\n",
            "Shape of X_train_tfidf: (40000, 5000)\n",
            "Shape of X_test_tfidf:  (10000, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# ü§ñ CELL 8: TRAIN THE MULTINOMIAL NAIVE BAYES CLASSIFIER\n",
        "# -------------------------------------------------------------\n",
        "# Purpose:\n",
        "# - Use the TF-IDF features to train a text classification model\n",
        "# - Algorithm: Multinomial Naive Bayes (good for word counts / TF-IDF)\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "# Initialize the Multinomial Naive Bayes model\n",
        "# alpha is the smoothing parameter (default = 1.0; 0.5 is often a good choice)\n",
        "model = MultinomialNB(alpha=0.5)\n",
        "\n",
        "# Fit the model on the training data\n",
        "# - X_train_tfidf: TF-IDF matrix of training reviews\n",
        "# - y_train: corresponding sentiment labels (\"positive\"/\"negative\")\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"‚úÖ Model training completed successfully!\")\n"
      ],
      "metadata": {
        "id": "KPTN_EV2UjH2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a2b75cc-bcbf-4917-d0ca-33598c64f8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model training completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# üìà CELL 9: MODEL EVALUATION ON TEST DATA\n",
        "# -------------------------------------------------------------\n",
        "# Purpose:\n",
        "# - Use the trained model to predict sentiments for test reviews\n",
        "# - Measure how well the model performs using:\n",
        "#       ‚úî Accuracy\n",
        "#       ‚úî Classification Report (precision, recall, F1-score)\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "# 1Ô∏è‚É£ Use the trained model to predict sentiment labels for test set\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# 2Ô∏è‚É£ Calculate accuracy: percentage of correct predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"üîç MODEL EVALUATION RESULTS\")\n",
        "print(\"----------------------------------------\")\n",
        "print(f\"‚úÖ Accuracy: {accuracy:.4f}\")   # 4 decimal places\n",
        "\n",
        "# 3Ô∏è‚É£ Display detailed metrics for each class (positive, negative)\n",
        "print(\"\\nüìä Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "VksUzK38WqYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f570467-7e22-4735-d698-cb6801951cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç MODEL EVALUATION RESULTS\n",
            "----------------------------------------\n",
            "‚úÖ Accuracy: 0.8597\n",
            "\n",
            "üìä Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.84      0.86      5000\n",
            "    positive       0.85      0.88      0.86      5000\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# üí¨ CELL 10: PREDICT SENTIMENT FOR CUSTOM USER INPUT\n",
        "# -------------------------------------------------------------\n",
        "# Purpose:\n",
        "# - Allow us (or students) to type any review sentence\n",
        "# - Use the trained model + TF-IDF vectorizer to predict:\n",
        "#       ‚Üí \"positive\" or \"negative\"\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "def predict_sentiment(review_text):\n",
        "    \"\"\"\n",
        "    Takes a raw review (string) as input and returns the predicted sentiment.\n",
        "\n",
        "    Steps:\n",
        "    1. Convert the input text into TF-IDF vector using the SAME vectorizer (tfidf)\n",
        "    2. Use the trained model (model) to predict the sentiment label\n",
        "    3. Return the predicted label\n",
        "    \"\"\"\n",
        "    # Transform the input text to TF-IDF vector (DO NOT fit again)\n",
        "    review_tfidf = tfidf.transform([review_text])\n",
        "\n",
        "    # Get model prediction\n",
        "    prediction = model.predict(review_tfidf)[0]\n",
        "\n",
        "    return prediction\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# üîé TEST THE FUNCTION WITH SAMPLE SENTENCES\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "sample_1 = \"I absolutely loved this movie, it was fantastic!\"\n",
        "sample_2 = \"This was the worst film I have seen, very boring and slow.\"\n",
        "\n",
        "print(\"üîπ Review 1:\", sample_1)\n",
        "print(\"   ‚Üí Predicted sentiment:\", predict_sentiment(sample_1))\n",
        "\n",
        "print(\"\\nüîπ Review 2:\", sample_2)\n",
        "print(\"   ‚Üí Predicted sentiment:\", predict_sentiment(sample_2))\n"
      ],
      "metadata": {
        "id": "l808XswsWyiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0677f181-4891-49bb-f265-ab229e46b3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Review 1: I absolutely loved this movie, it was fantastic!\n",
            "   ‚Üí Predicted sentiment: positive\n",
            "\n",
            "üîπ Review 2: This was the worst film I have seen, very boring and slow.\n",
            "   ‚Üí Predicted sentiment: negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# üåê CELL 11 (v2): GRADIO APP WITH CONFIDENCE SCORES\n",
        "# -------------------------------------------------------------\n",
        "# Purpose:\n",
        "# - Build a Gradio UI that:\n",
        "#     1) Takes a movie review as input\n",
        "#     2) Uses the SAME trained model + TF-IDF vectorizer\n",
        "#     3) Outputs:\n",
        "#          - Predicted label (positive / negative)\n",
        "#          - Confidence scores for each class\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def gradio_sentiment_with_confidence(review_text):\n",
        "    \"\"\"\n",
        "    Wrapper function for Gradio.\n",
        "\n",
        "    Input:\n",
        "        review_text (str): Raw movie review from user.\n",
        "\n",
        "    Output:\n",
        "        - A dictionary mapping each class to its probability.\n",
        "          Gradio's Label component can display this nicely.\n",
        "    \"\"\"\n",
        "    # 1Ô∏è‚É£ Convert input text to TF-IDF vector using SAME vectorizer\n",
        "    review_tfidf = tfidf.transform([review_text])\n",
        "\n",
        "    # 2Ô∏è‚É£ Get probability for each class from the trained model\n",
        "    #    model.classes_ ‚Üí array of class labels (e.g. ['negative', 'positive'])\n",
        "    #    model.predict_proba(...) ‚Üí probabilities for each class\n",
        "    proba = model.predict_proba(review_tfidf)[0]   # 1D array of probs\n",
        "    classes = model.classes_                      # class names in same order\n",
        "\n",
        "    # 3Ô∏è‚É£ Build a dictionary: {\"negative\": prob_neg, \"positive\": prob_pos}\n",
        "    proba_dict = {cls: float(p) for cls, p in zip(classes, proba)}\n",
        "\n",
        "    # Optional: you could also compute the top predicted label if needed:\n",
        "    # predicted_label = classes[proba.argmax()]\n",
        "\n",
        "    return proba_dict   # Gradio Label will show this as scores per class\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# üß± BUILDING THE GRADIO INTERFACE\n",
        "# -------------------------------------------------------------\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "    # Title / Description\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # üé¨ IMDB Movie Review Sentiment Analyzer (with Confidence)\n",
        "\n",
        "        Type a movie review below and the model will predict whether\n",
        "        it is **positive** or **negative**, along with confidence scores.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Text input box\n",
        "    input_text = gr.Textbox(\n",
        "        label=\"Enter a movie review\",\n",
        "        placeholder=\"Example: I absolutely loved this movie, it was fantastic!\",\n",
        "        lines=4\n",
        "    )\n",
        "\n",
        "    # Output label that shows class ‚Üí probability mapping\n",
        "    output_scores = gr.Label(\n",
        "        label=\"Predicted Sentiment (with confidence scores)\"\n",
        "    )\n",
        "\n",
        "    # Button for triggering prediction\n",
        "    analyze_button = gr.Button(\"Analyze Sentiment\")\n",
        "\n",
        "    # Connect button click to our function\n",
        "    analyze_button.click(\n",
        "        fn=gradio_sentiment_with_confidence,  # function defined above\n",
        "        inputs=input_text,                    # user review text\n",
        "        outputs=output_scores                 # dict of {class: probability}\n",
        "    )\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# üöÄ LAUNCH THE APP\n",
        "# -------------------------------------------------------------\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "id": "Ky_NzFTDXBb-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "83294825-f292-4eb3-ef07-378cc3697b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://82071a88a690a11477.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://82071a88a690a11477.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# üíæ CELL 12: SAVE TRAINED MODEL & TF-IDF VECTORIZER TO DISK\n",
        "# -------------------------------------------------------------\n",
        "# Purpose:\n",
        "# - In real projects, you do NOT want to retrain the model every time.\n",
        "# - Instead, you:\n",
        "#     1) Train once\n",
        "#     2) Save the model + vectorizer to files\n",
        "#     3) Load them later in a new script / app / server\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "import joblib  # library for saving and loading Python objects efficiently\n",
        "\n",
        "# 1Ô∏è‚É£ Define file names for saving the model and vectorizer\n",
        "model_filename = \"sentiment_nb_model.joblib\"\n",
        "tfidf_filename = \"tfidf_vectorizer.joblib\"\n",
        "\n",
        "# 2Ô∏è‚É£ Save the trained Naive Bayes model\n",
        "joblib.dump(model, model_filename)\n",
        "print(f\"‚úÖ Model saved as: {model_filename}\")\n",
        "\n",
        "# 3Ô∏è‚É£ Save the fitted TF-IDF vectorizer\n",
        "joblib.dump(tfidf, tfidf_filename)\n",
        "print(f\"‚úÖ TF-IDF vectorizer saved as: {tfidf_filename}\")\n"
      ],
      "metadata": {
        "id": "ucY66Mw-YDGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03145cb1-90bd-4ce9-f1ae-04da75d0c9ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model saved as: sentiment_nb_model.joblib\n",
            "‚úÖ TF-IDF vectorizer saved as: tfidf_vectorizer.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# üåê CELL 13 (Enhanced): GRADIO APP ‚Äî SINGLE PREDICTION + CSV UPLOAD\n",
        "# -------------------------------------------------------------\n",
        "# Purpose:\n",
        "# - Load trained Naive Bayes model + TF-IDF vectorizer from disk\n",
        "# - Provide TWO functionalities inside one Gradio app:\n",
        "#     1. Single sentiment prediction (nicely formatted with emoji + colored background)\n",
        "#     2. CSV upload ‚Üí bulk sentiment predictions\n",
        "#        + Bar chart of sentiment distribution\n",
        "#        + Downloadable CSV with predictions\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "import joblib         # To load saved model + vectorizer\n",
        "import gradio as gr   # For the UX app\n",
        "import pandas as pd   # For CSV processing\n",
        "import matplotlib.pyplot as plt  # For plotting bar chart\n",
        "import os             # For handling file paths\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 1Ô∏è‚É£ LOAD MODEL AND VECTORIZER\n",
        "# -------------------------------------------------------------\n",
        "loaded_model = joblib.load(\"sentiment_nb_model.joblib\")\n",
        "loaded_tfidf = joblib.load(\"tfidf_vectorizer.joblib\")\n",
        "\n",
        "print(\"‚úÖ Model and vectorizer loaded successfully!\")\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 2Ô∏è‚É£ FUNCTION FOR SINGLE PREDICTION (WITH EMOJI + COLORED BACKGROUND)\n",
        "# -------------------------------------------------------------\n",
        "def predict_single_review(review_text):\n",
        "    \"\"\"\n",
        "    Takes one review text ‚Üí returns sentiment as an HTML block:\n",
        "        - Emoji\n",
        "        - Bold label\n",
        "        - Confidence\n",
        "        - Colored background (green for positive, red for negative)\n",
        "    \"\"\"\n",
        "    # Handle empty input gracefully\n",
        "    if not isinstance(review_text, str) or review_text.strip() == \"\":\n",
        "        return \"<div style='padding:10px; border-radius:8px; background-color:#fff3cd;'>‚ö†Ô∏è Please enter a review.</div>\"\n",
        "\n",
        "    # Transform using loaded vectorizer\n",
        "    vector = loaded_tfidf.transform([review_text])\n",
        "\n",
        "    # Predict class label\n",
        "    pred = loaded_model.predict(vector)[0]\n",
        "\n",
        "    # Get confidence scores\n",
        "    probs = loaded_model.predict_proba(vector)[0]\n",
        "    confidence = probs.max()  # highest probability\n",
        "\n",
        "    # Decide background color and emoji based on prediction\n",
        "    if pred == \"positive\":\n",
        "        bg_color = \"#d4edda\"   # light green\n",
        "        emoji = \"üòä\"\n",
        "        label_text = \"Positive\"\n",
        "    else:\n",
        "        bg_color = \"#f8d7da\"   # light red\n",
        "        emoji = \"üòû\"\n",
        "        label_text = \"Negative\"\n",
        "\n",
        "    # Return HTML string that Gradio will render\n",
        "    html = f\"\"\"\n",
        "    <div style=\"\n",
        "        background-color:{bg_color};\n",
        "        padding:15px;\n",
        "        border-radius:10px;\n",
        "        border:1px solid #ccc;\n",
        "        font-size:16px;\">\n",
        "        <strong>{emoji} {label_text}</strong><br/>\n",
        "        Confidence: {confidence:.2f}\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    return html\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 3Ô∏è‚É£ FUNCTION FOR BULK CSV PREDICTION + BAR CHART + DOWNLOAD\n",
        "# -------------------------------------------------------------\n",
        "def predict_csv(file):\n",
        "    \"\"\"\n",
        "    Takes an uploaded CSV file with a 'review' column.\n",
        "    Returns:\n",
        "        - DataFrame with an added 'predicted_sentiment' column\n",
        "        - Bar chart of sentiment distribution\n",
        "        - Path to downloadable CSV file with predictions\n",
        "    \"\"\"\n",
        "    # Read the uploaded CSV (Gradio passes a tempfile-like object)\n",
        "    df = pd.read_csv(file.name)\n",
        "\n",
        "    # Check if 'review' column exists\n",
        "    if \"review\" not in df.columns:\n",
        "        raise ValueError(\"CSV must contain a 'review' column.\")\n",
        "\n",
        "    # Transform all reviews into TF-IDF vectors\n",
        "    vectors = loaded_tfidf.transform(df[\"review\"])\n",
        "\n",
        "    # Predict for all rows\n",
        "    df[\"predicted_sentiment\"] = loaded_model.predict(vectors)\n",
        "\n",
        "    # ----- Create bar chart of sentiment distribution -----\n",
        "    sentiment_counts = df[\"predicted_sentiment\"].value_counts()\n",
        "\n",
        "    # Create a matplotlib figure\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.bar(sentiment_counts.index, sentiment_counts.values)\n",
        "    ax.set_title(\"Sentiment Distribution\")\n",
        "    ax.set_xlabel(\"Sentiment\")\n",
        "    ax.set_ylabel(\"Count\")\n",
        "\n",
        "    # Optional: add value labels on top of bars\n",
        "    for i, v in enumerate(sentiment_counts.values):\n",
        "        ax.text(i, v + 0.5, str(v), ha='center')\n",
        "\n",
        "    # ----- Save CSV with predictions for download -----\n",
        "    output_csv_path = \"predicted_sentiments.csv\"\n",
        "    df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "    # Return:\n",
        "    # 1) DataFrame ‚Üí visible in the UI\n",
        "    # 2) Plot ‚Üí bar chart of distribution\n",
        "    # 3) File path ‚Üí Gradio File component will use this for download\n",
        "    return df, fig, output_csv_path\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 4Ô∏è‚É£ BUILD GRADIO APP (TWO TABS, ENHANCED)\n",
        "# -------------------------------------------------------------\n",
        "with gr.Blocks() as app:\n",
        "\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # üé¨ IMDB Sentiment Analysis App\n",
        "        ### Powered by Naive Bayes + TF-IDF\n",
        "        ---\n",
        "        Use this tool to analyze **single reviews** or upload a **CSV** for bulk analysis.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # ---------- TAB 1: Single Review Prediction ----------\n",
        "    with gr.Tab(\"üî∏ Single Review Prediction\"):\n",
        "        input_text = gr.Textbox(\n",
        "            label=\"Enter a movie review\",\n",
        "            placeholder=\"Type your review here...\",\n",
        "            lines=4\n",
        "        )\n",
        "        # Use HTML so we can style background colors\n",
        "        single_output = gr.HTML(label=\"Prediction\")\n",
        "        single_button = gr.Button(\"Analyze Sentiment\")\n",
        "        single_button.click(\n",
        "            fn=predict_single_review,\n",
        "            inputs=input_text,\n",
        "            outputs=single_output\n",
        "        )\n",
        "\n",
        "    # ---------- TAB 2: CSV Upload for Bulk Prediction ----------\n",
        "    with gr.Tab(\"üìÇ CSV Upload for Bulk Prediction\"):\n",
        "        csv_input = gr.File(label=\"Upload CSV with 'review' column\")\n",
        "        csv_output = gr.DataFrame(label=\"Prediction Output\")\n",
        "        csv_plot = gr.Plot(label=\"Sentiment Distribution\")\n",
        "        csv_download = gr.File(label=\"Download Predictions CSV\")\n",
        "\n",
        "        csv_button = gr.Button(\"Process CSV\")\n",
        "        csv_button.click(\n",
        "            fn=predict_csv,\n",
        "            inputs=csv_input,\n",
        "            outputs=[csv_output, csv_plot, csv_download]\n",
        "        )\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# 5Ô∏è‚É£ LAUNCH THE APP\n",
        "# -------------------------------------------------------------\n",
        "app.launch(share=True)\n"
      ],
      "metadata": {
        "id": "sCiE8pQSXl9I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "45687a91-89a9-4d9c-e5d6-c09ba6f69572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model and vectorizer loaded successfully!\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ca9420a73ad81681d2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ca9420a73ad81681d2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A40eehNOYY1U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}